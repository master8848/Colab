{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/master8848/Colab/blob/NSE_BOT_2023_04_09/Copy_of_Welcome_To_Colaboratory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nsepython"
      ],
      "metadata": {
        "id": "R2uU_1vp1aIR",
        "outputId": "b5fd763e-daca-464c-dd7b-1929fe2bf061",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting nsepython\n",
            "  Downloading nsepython-0.0.973-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from nsepython) (2.27.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from nsepython) (1.10.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from nsepython) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.9/dist-packages (from pandas->nsepython) (1.22.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->nsepython) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->nsepython) (2.8.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->nsepython) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->nsepython) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->nsepython) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->nsepython) (1.26.15)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->nsepython) (1.16.0)\n",
            "Installing collected packages: nsepython\n",
            "Successfully installed nsepython-0.0.973\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are many technical analysis tools available for traders, and the best one depends on individual preferences and trading styles. Here are some popular technical analysis tools:\n",
        "\n",
        "\n",
        "\n",
        "> Moving Averages - used to identify trends and potential reversal points\n",
        "\n",
        "> Relative Strength Index (RSI) - a momentum oscillator used to measure the strength of price movements\n",
        "\n",
        "> Bollinger Bands - used to measure volatility and identify potential trend reversals\n",
        "\n",
        "> Fibonacci retracement - used to identify potential levels of support and resistance\n",
        "\n",
        "\n",
        "> Ichimoku Cloud - a trend-following indicator that shows support and resistance levels, as well as the momentum of a trend\n",
        "\n",
        "It's important to note that technical analysis tools should not be relied on exclusively. A comprehensive trading strategy should also include fundamental analysis and risk management techniques."
      ],
      "metadata": {
        "id": "1pGP464S4f8X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "While it is possible to modify the code to incorporate Deep Reinforcement Learning, Natural Language Processing, Neural Networks, Genetic Algorithms, and Fuzzy Logic, it would require a significant amount of additional code and expertise in each of these areas.\n",
        "\n",
        "Deep Reinforcement Learning involves training an agent to learn from its environment by taking actions and receiving feedback. This could be used to optimize trading decisions based on historical market data. Natural Language Processing could be used to analyze news articles and social media to identify sentiment and make trading decisions based on that information.\n",
        "\n",
        "Neural Networks could be used to identify patterns in historical data and make predictions about future market trends. Genetic Algorithms could be used to optimize trading strategies based on a set of parameters.\n",
        "\n",
        "Fuzzy Logic could be used to incorporate subjective or qualitative information into the trading decisions, such as the trader's risk tolerance or market volatility.\n",
        "\n",
        "While these techniques have shown promise in the field of trading, they require significant computational resources and expertise to implement effectively. As such, it may be more practical to start with a simpler trading strategy and gradually incorporate these more advanced techniques over time as you gain more experience and resources."
      ],
      "metadata": {
        "id": "_kZc0Bck5miF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # import pandas as pd\n",
        "# # import numpy as np\n",
        "# # import yfinance as yf\n",
        "\n",
        "# # # Define the strategy\n",
        "# # def moving_average_strategy(ticker, short_window, long_window):\n",
        "# #     # Retrieve the stock data\n",
        "# #     stock_data = yf.download(ticker, start='2016-01-01', end='2016-01-30')\n",
        "# #     # Create short and long moving averages\n",
        "# #     stock_data['SMA_short'] = stock_data['Close'].rolling(window=short_window).mean()\n",
        "# #     stock_data['SMA_long'] = stock_data['Close'].rolling(window=long_window).mean()\n",
        "# #     # Generate buy and sell signals\n",
        "# #     stock_data['Signal'] = np.where(stock_data['SMA_short'] > stock_data['SMA_long'], 1, 0)\n",
        "# #     stock_data['Position'] = stock_data['Signal'].diff()\n",
        "# #     # Plot the signals and positions\n",
        "# #     stock_data[['Close', 'SMA_short', 'SMA_long']].plot(figsize=(10,6))\n",
        "# #     stock_data['Position'].plot(ylim=[-1, 1], secondary_y=True)\n",
        "# #     return stock_data\n",
        "\n",
        "# # # Apply the strategy to Nifty 50\n",
        "# # nifty50_data = moving_average_strategy('Reliance', 20, 50)\n",
        "\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# from sklearn.preprocessing import MinMaxScaler\n",
        "# from keras.models import Sequential\n",
        "# from keras.layers import Dense, Dropout, LSTM\n",
        "\n",
        "# import yfinance as yf\n",
        "\n",
        "# # Define the ticker symbol\n",
        "# tickerSymbol = 'AAPL'\n",
        "\n",
        "# # Get data on the ticker\n",
        "# tickerData = yf.Ticker(tickerSymbol)\n",
        "\n",
        "# # Get the historical prices for this ticker\n",
        "# df = tickerData.history(period='1d', start='2010-1-1', end='2015-1-1')\n",
        "\n",
        "# # Load data\n",
        "# # df = pd.read_csv('data.csv')\n",
        "# df = df.sort_values('Date')\n",
        "# df = df.set_index('Date')\n",
        "\n",
        "# # Split data into training and testing sets\n",
        "# split_date = '2019-01-01'\n",
        "# train_df = df.loc[df.index <= split_date]\n",
        "# test_df = df.loc[df.index > split_date]\n",
        "\n",
        "# # Scale data\n",
        "# scaler = MinMaxScaler()\n",
        "# train_data = scaler.fit_transform(train_df)\n",
        "# test_data = scaler.transform(test_df)\n",
        "\n",
        "# # Define function to create dataset for LSTM\n",
        "# def create_dataset(data, lookback=1):\n",
        "#     X, Y = [], []\n",
        "#     for i in range(lookback, len(data)):\n",
        "#         X.append(data[i-lookback:i, :])\n",
        "#         Y.append(data[i, 0])\n",
        "#     X = np.array(X)\n",
        "#     Y = np.array(Y)\n",
        "#     return X, Y\n",
        "\n",
        "# # Define LSTM model\n",
        "# model = Sequential()\n",
        "# model.add(LSTM(units=50, return_sequences=True, input_shape=(lookback, num_features)))\n",
        "# model.add(Dropout(0.2))\n",
        "# model.add(LSTM(units=50, return_sequences=True))\n",
        "# model.add(Dropout(0.2))\n",
        "# model.add(LSTM(units=50))\n",
        "# model.add(Dropout(0.2))\n",
        "# model.add(Dense(units=1))\n",
        "\n",
        "# # Compile model\n",
        "# model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# # Train model\n",
        "# model.fit(X_train, y_train, epochs=100, batch_size=32)\n",
        "\n",
        "# # Make predictions on test data\n",
        "# test_inputs = train_df[-lookback:].values.reshape(-1, num_features)\n",
        "# test_inputs = scaler.transform(test_inputs)\n",
        "# test_predictions = []\n",
        "# for i in range(len(test_df)):\n",
        "#     test_prediction = model.predict(test_inputs.reshape(1, lookback, num_features))\n",
        "#     test_predictions.append(test_prediction)\n",
        "#     test_inputs = np.concatenate((test_inputs[1:], test_prediction), axis=0)\n",
        "\n",
        "# # Scale predictions back to original range\n",
        "# test_predictions = scaler.inverse_transform(np.array(test_predictions).reshape(-1, 1))\n",
        "\n",
        "# # Create DataFrame of predictions\n",
        "# predictions_df = pd.DataFrame(test_predictions, index=test_df.index, columns=['Predictions'])\n",
        "\n",
        "# # Create DataFrame of actual prices\n",
        "# actual_prices_df = test_df['Close']\n",
        "\n",
        "# # Concatenate actual prices and predictions into single DataFrame\n",
        "# results_df = pd.concat([actual_prices_df, predictions_df], axis=1)\n",
        "\n",
        "# # Calculate trading signals based on predicted prices\n",
        "# results_df['Signal'] = np.where(results_df['Predictions'] > results_df['Close'], 1, -1)\n",
        "\n",
        "# # Calculate returns based on trading signals\n",
        "# results_df['Returns'] = results_df['Close'].pct_change() * results_df['Signal'].shift(1)\n",
        "\n",
        "# # Calculate cumulative returns\n",
        "# cumulative_returns = (1 + results_df['Returns']).cumprod()\n",
        "\n",
        "# # Plot results\n",
        "# import matplotlib.pyplot as plt\n",
        "# plt.plot(cumulative_returns)\n",
        "# plt.xlabel('Date')\n",
        "# plt.ylabel('Cumulative Returns')\n",
        "# plt.show()\n",
        "\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# from sklearn.preprocessing import MinMaxScaler\n",
        "# from keras.models import Sequential\n",
        "# from keras.layers import Dense, Dropout, LSTM\n",
        "\n",
        "# import yfinance as yf\n",
        "\n",
        "# # Define the ticker symbol\n",
        "# tickerSymbol = 'AAPL'\n",
        "\n",
        "# # Get data on the ticker\n",
        "# tickerData = yf.Ticker(tickerSymbol)\n",
        "\n",
        "# # Get the historical prices for this ticker\n",
        "# df = tickerData.history(period='1d', start='2010-1-1', end='2015-1-1')\n",
        "\n",
        "# # Load data\n",
        "# # df = pd.read_csv('data.csv')\n",
        "# df = df.sort_values('Date')\n",
        "# df.index.name = 'Date'\n",
        "# # print(df)\n",
        "# # Split data into training and testing sets\n",
        "# split_date = '2014-01-01'\n",
        "# train_df = df.loc[df.index <= split_date]\n",
        "# test_df = df.loc[df.index > split_date]\n",
        "\n",
        "# def create_dataset(data, lookback):\n",
        "#     X, y = [], []\n",
        "#     for i in range(lookback, len(data)):\n",
        "#         X.append(data[i-lookback:i])\n",
        "#         y.append(data[i])\n",
        "#     X, y = np.array(X), np.array(y)\n",
        "#     X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
        "#     return X, y\n",
        "# # Scale data\n",
        "# scaler = MinMaxScaler()\n",
        "# train_data = scaler.fit_transform(train_df)\n",
        "# test_df.fillna(test_df.mean(), inplace=True)\n",
        "# test_data = scaler.transform(test_df)\n",
        "\n",
        "# # Define function to create dataset for LSTM\n",
        "# lookback = 60\n",
        "# num_features = 1\n",
        "# X_train, y_train = create_dataset(train_data, lookback)\n",
        "\n",
        "# # Define LSTM model\n",
        "# model = Sequential()\n",
        "# model.add(LSTM(units=50, return_sequences=True, input_shape=(lookback, num_features)))\n",
        "# model.add(Dropout(0.2))\n",
        "# model.add(LSTM(units=50, return_sequences=True))\n",
        "# model.add(Dropout(0.2))\n",
        "# model.add(LSTM(units=50))\n",
        "# model.add(Dropout(0.2))\n",
        "# model.add(Dense(units=1))\n",
        "\n",
        "# # Compile model\n",
        "# model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# # Train model\n",
        "# model.fit(X_train, y_train, epochs=100, batch_size=32)\n",
        "\n",
        "# # Make predictions on test data\n",
        "# test_inputs = test_df[-lookback:].values.reshape(1, lookback, num_features)\n",
        "# test_inputs = scaler.transform(test_inputs)\n",
        "# test_predictions = []\n",
        "# for i in range(len(test_df)):\n",
        "#     test_prediction = model.predict(test_inputs)\n",
        "#     test_predictions.append(test_prediction[0])\n",
        "#     test_inputs = np.concatenate((test_inputs[:, 1:, :], test_prediction.reshape(1, 1, num_features)), axis=1)\n",
        "\n",
        "# # Scale predictions back to original range\n",
        "# test_predictions = scaler.inverse_transform(np.array(test_predictions).reshape(-1, 1))\n",
        "\n",
        "# # Create DataFrame of predictions\n",
        "# predictions_df = pd.DataFrame(test_predictions, index=test_df.index, columns=['Predictions'])\n",
        "\n",
        "# # Create DataFrame of actual prices\n",
        "# actual_prices_df = test_df['Close']\n",
        "\n",
        "# # Concatenate actual prices and predictions into single DataFrame\n",
        "# results_df = pd.concat([actual_prices_df, predictions_df], axis=1)\n",
        "\n",
        "# # Calculate trading signals based on predicted prices\n",
        "# results_df['Signal'] = np.where(results_df['Predictions'] > results_df['Close'], 1, -1)\n",
        "\n",
        "# # Calculate returns based on trading signals\n",
        "# results_df\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM\n",
        "\n",
        "import yfinance as yf\n",
        "\n",
        "# Define the ticker symbol\n",
        "tickerSymbol = 'AAPL'\n",
        "\n",
        "# Get data on the ticker\n",
        "tickerData = yf.Ticker(tickerSymbol)\n",
        "\n",
        "# Get the historical prices for this ticker\n",
        "df = tickerData.history(period='1d', start='2010-1-1', end='2015-1-1')\n",
        "\n",
        "# Load data\n",
        "# df = pd.read_csv('data.csv')\n",
        "df = df.sort_values('Date')\n",
        "df.index.name = 'Date'\n",
        "# print(df)\n",
        "# Split data into training and testing sets\n",
        "split_date = '2014-01-01'\n",
        "train_df = df.loc[df.index <= split_date]\n",
        "test_df = df.loc[df.index > split_date].copy()\n",
        "\n",
        "def create_dataset(data, lookback):\n",
        "    X, y = [], []\n",
        "    for i in range(lookback, len(data)):\n",
        "        X.append(data[i-lookback:i])\n",
        "        y.append(data[i])\n",
        "    X, y = np.array(X), np.array(y)\n",
        "    X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
        "    return X, y\n",
        "# Scale data\n",
        "scaler = MinMaxScaler()\n",
        "train_data = scaler.fit_transform(train_df)\n",
        "test_data = scaler.transform(test_df)\n",
        "\n",
        "# Define function to create dataset for LSTM\n",
        "lookback = 60\n",
        "num_features = 1\n",
        "X_train, y_train = create_dataset(train_data, lookback)\n",
        "\n",
        "# Scale y_train\n",
        "scaler_y = MinMaxScaler()\n",
        "y_train = scaler_y.fit_transform(y_train.reshape(-1,1))\n",
        "\n",
        "# Define LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=50, return_sequences=True, input_shape=(lookback, num_features)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(units=50, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(units=50))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=1))\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=32)\n",
        "\n",
        "# Make predictions on test data\n",
        "test_inputs = test_df[-lookback:].values.reshape(1, lookback, num_features)\n",
        "test_inputs = scaler.transform(test_inputs)\n",
        "test_predictions = []\n",
        "for i in range(len(test_df)):\n",
        "    test_prediction = model.predict(test_inputs)\n",
        "    test_predictions.append(test_prediction[0])\n",
        "    test_inputs = np.concatenate((test_inputs[:, 1:, :], test_prediction.reshape(1, 1, num_features)), axis=1)\n",
        "\n",
        "# Scale predictions back to original range\n",
        "test_predictions = scaler_y.inverse_transform(np.array(test_predictions).reshape(-1, 1))\n",
        "\n",
        "# Create DataFrame of\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "ulG4wHSSzvcj",
        "outputId": "eb41f95f-1097-494b-fae9-d2273d7f68c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-d7cc109d8894>\u001b[0m in \u001b[0;36m<cell line: 250>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0mlookback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0mnum_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;31m# Scale y_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-d7cc109d8894>\u001b[0m in \u001b[0;36mcreate_dataset\u001b[0;34m(data, lookback)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;31m# Scale data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    296\u001b[0m            [5, 6]])\n\u001b[1;32m    297\u001b[0m     \"\"\"\n\u001b[0;32m--> 298\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reshape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 397320 into shape (946,60,1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nsepy import get_history\n",
        "from datetime import date\n",
        "\n",
        "Rel = get_history(symbol='RELIANCE', start=date(2021,1,1), end=date(2021,1,15))\n",
        "print(Rel)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "Rm1PRaZY-EWw",
        "outputId": "1421bb06-892a-4315-aac9-c322955dbe54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TooManyRedirects",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTooManyRedirects\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-1b5417037303>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mRel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'RELIANCE'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2021\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2021\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/nsepy/history.py\u001b[0m in \u001b[0;36mget_history\u001b[0;34m(symbol, start, end, index, futures, option_type, expiry_date, strike_price, series)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_history_quanta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/nsepy/history.py\u001b[0m in \u001b[0;36mget_history_quanta\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_history_quanta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaling\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m     df = url_to_df(url=url,\n\u001b[0m\u001b[1;32m    144\u001b[0m                    \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m                    \u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/nsepy/history.py\u001b[0m in \u001b[0;36murl_to_df\u001b[0;34m(url, params, schema, headers, scaling)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0murl_to_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m     \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m     \u001b[0mbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lxml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     tp = ParseTables(soup=bs,\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/nsepy/commons.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'get'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproxy\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'post'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GET'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    527\u001b[0m         }\n\u001b[1;32m    528\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    665\u001b[0m             \u001b[0;31m# Redirect resolving generator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0mgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve_redirects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    668\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m             \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    665\u001b[0m             \u001b[0;31m# Redirect resolving generator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0mgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve_redirects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    668\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m             \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mresolve_redirects\u001b[0;34m(self, resp, req, stream, timeout, verify, cert, proxies, yield_requests, **adapter_kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_redirects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTooManyRedirects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Exceeded {} redirects.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_redirects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;31m# Release the connection back into the pool.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTooManyRedirects\u001b[0m: Exceeded 30 redirects."
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}